{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FyN1vy4o4U0",
        "outputId": "ffd67a78-52ac-4936-90f0-4620effc9a5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 31.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 64.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 55.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 59.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpKps6wStnUv"
      },
      "outputs": [],
      "source": [
        "# !pip install bert-for-tf2 >> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfqDtcrPss5B"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorflow==2.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFEZH0gioR_n"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optimizor\n",
        "from transformers import BertModel\n",
        "\n",
        "# import bert\n",
        "# from bert import BertModelLayer\n",
        "# from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
        "# from bert.tokenization.bert_tokenization import FullTokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_XmvX_npDmW",
        "outputId": "c7e185a2-44f4-46db-aeb9-c89afe3cdaf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OlcvGWReJMuyYQuOZm149vHWwPtlboR6\n",
            "To: /content/train.csv\n",
            "100% 799k/799k [00:00<00:00, 116MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Oi5cRlTybuIF2Fl5Bfsr-KkqrXrdt77w\n",
            "To: /content/valid.csv\n",
            "100% 43.3k/43.3k [00:00<00:00, 57.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ep9H6-HvhB4utJRLVcLzieWNUSG3P_uF\n",
            "To: /content/test.csv\n",
            "100% 43.1k/43.1k [00:00<00:00, 52.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1OlcvGWReJMuyYQuOZm149vHWwPtlboR6 --output train.csv\n",
        "!gdown --id 1Oi5cRlTybuIF2Fl5Bfsr-KkqrXrdt77w --output valid.csv\n",
        "!gdown --id 1ep9H6-HvhB4utJRLVcLzieWNUSG3P_uF --output test.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6rGrzKurx16"
      },
      "outputs": [],
      "source": [
        "tstart=191\n",
        "tend=240"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbxOft7uommW"
      },
      "outputs": [],
      "source": [
        "train1 = pd.read_csv(\"train.csv\")\n",
        "valid = pd.read_csv(\"valid.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "train=train1[:tend]\n",
        "test=test[:100]\n",
        "valid=valid.sample(60)\n",
        "# train = train.append(valid).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQFb1Wy0tw5c",
        "outputId": "146485d3-ff72-4dd8-dd73-c4b522731db9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  text                intent\n",
            "486                          give this album one stars              RateBook\n",
            "501                 please look up the tv show  vanity    SearchCreativeWork\n",
            "667                      is the two gladiators playing  SearchScreeningEvent\n",
            "465    give 4 points to the person and the common good              RateBook\n",
            "464         give the current textbook a rating of five              RateBook\n",
            "409       rate the sneetches and other stories a three              RateBook\n",
            "227  i need to know the weather for jan  the 3rd in...            GetWeather\n",
            "119  i need a table for 4 please confirm the reserv...        BookRestaurant\n",
            "574   find me the soundtrack live at the greek theatre    SearchCreativeWork\n",
            "450          give the zenith angle one out of 6 points              RateBook\n",
            "497                  rate the three junes one out of 6              RateBook\n",
            "626  is the nightmare showing six hours from now at...  SearchScreeningEvent\n",
            "669                   find the movie schedule close by  SearchScreeningEvent\n",
            "642             check the schedule for bow tie cinemas  SearchScreeningEvent\n",
            "243                  what s the weather in benton city            GetWeather\n",
            "568   can you search the book  paris - when it sizzles    SearchCreativeWork\n",
            "535  can you find me the work titled music for mill...    SearchCreativeWork\n",
            "42         add the 40 cal tune to the laundry playlist         AddToPlaylist\n",
            "560              look for the album slave to the grind    SearchCreativeWork\n",
            "283              will it be hotter in pr at 23 o clock            GetWeather\n",
            "152  book me a table for 5 this year at cherwell bo...        BookRestaurant\n",
            "150  book spot for mavis  sheila and i in syria at ...        BookRestaurant\n",
            "202          tell me the weather forecast for gibsland            GetWeather\n",
            "697  what s the movie schedule at great escape thea...  SearchScreeningEvent\n",
            "117  i need a table for 5 at a highly rated gastrop...        BookRestaurant\n",
            "223      will it be colder here in 48 and a half weeks            GetWeather\n",
            "288  what is the forecast for starting at three a m...            GetWeather\n",
            "239      what is the weather forecast nearby nicodemus            GetWeather\n",
            "335                             play jill sobule album             PlayMusic\n",
            "651  when is the outer space connection playing at ...  SearchScreeningEvent\n",
            "579         find the album orphan girl at the cemetery    SearchCreativeWork\n",
            "176         i want to book a restaurant for ten people        BookRestaurant\n",
            "576       find a creative work called fire in the hole    SearchCreativeWork\n",
            "455  give one of 6 points to who will cry when you die              RateBook\n",
            "237          what is the forecast for waurika in samoa            GetWeather\n",
            "129  book a reservation for 8 people in wardville  ...        BookRestaurant\n",
            "248         what kind of weather is forecast in ms now            GetWeather\n",
            "461               give the american scene 2 of 6 stars              RateBook\n",
            "221  what will the weather be nineteen hours from n...            GetWeather\n",
            "285  what is the forecast for this afternoon for bl...            GetWeather\n",
            "625  i want to see doa: dead or alive at loews cine...  SearchScreeningEvent\n",
            "258  what is the forecast for beginning on nov  17 ...            GetWeather\n",
            "240      what will the weather be in nov  in brookneal            GetWeather\n",
            "380                       play an ep from mike harding             PlayMusic\n",
            "185  i want to book a churrascaria in romeoville at...        BookRestaurant\n",
            "375  play the top music from the railway children o...             PlayMusic\n",
            "79        add tommy johnson to the metalsucks playlist         AddToPlaylist\n",
            "588  please search for the journal of official stat...    SearchCreativeWork\n",
            "466                give a four rating to a world apart              RateBook\n",
            "359             play dance with the devil by mr  lordi             PlayMusic\n",
            "219  will it be stormy in the ouachita national forest            GetWeather\n",
            "421                   rate this textbook four out of 6              RateBook\n",
            "360                               play music from 1996             PlayMusic\n",
            "438                     rate the current novel 3 stars              RateBook\n",
            "27              add this track to my hands up playlist         AddToPlaylist\n",
            "395            let s hear good mohammad mamle on vimeo             PlayMusic\n",
            "317       play anything jd natasha did in the thirties             PlayMusic\n",
            "388  i want to hear soundtrack music on youtube fro...             PlayMusic\n",
            "477         give 5 of 6 stars to expressive processing              RateBook\n",
            "396  please play a sound track from the fifties tha...             PlayMusic\n"
          ]
        }
      ],
      "source": [
        "print(valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300,
          "referenced_widgets": [
            "473d6eb0b1c74041aa6dcd0e23ec93c6",
            "a3048822791d417f9822780bd436d0f2",
            "d196481c7d85407687b802e2997b5d53",
            "d33f6fdc6d8c498b831e44a20bc1f205",
            "5c98d3f02dd64af78553ada2e702485e",
            "7ab82d9809d44c64a38e15f902bd8f20",
            "ff95d213550240738801915360b16b66",
            "dfc65a49583549f69bed3f0a234b3d3b",
            "b9e5ecc5123346ef81379aa89449428c",
            "6f09dc2bcc3a4b9c87f5cbb6eb55c6c8",
            "c6449f05f56640e69aca3f5b02a1ea73",
            "ec1958b31b9e48dfb41ef49f18d2f6af",
            "b42e0fd07d77464cbbd1edb920bbb6b1",
            "7eeef912c6114c5c856e1745876c75eb",
            "ff8cdcecf4b848cba5aed0327bd67432",
            "9154231defc44ed7b1998db883cffe2f",
            "c092f5eb50b74e20942ef7db335418b8",
            "a48fad29930d498ea7a80c7c9e1aa77c",
            "b43338cb6e8b41a9b8c367c928367af0",
            "9ade3851ea9c4f5695a54639b2d3956e",
            "19590b55224c4ae8a83bf714c7efbabf",
            "6b2c08f3c3704154876537938eb36cf1",
            "179a4d781b6647a7ae80f0bfd3a9641e",
            "a579e767b4484a7090191cf64027054c",
            "66fafb53efda49818aec2622a7d8ff46",
            "ea00c0a68c6f48eca082e9e370ff240b",
            "a9f0ea4225454b97923d5aa4cda7eefc",
            "417497019aa64f47a35ba653912dfedf",
            "f7fd6ff052584333b38ac3035d6caad3",
            "1d0ebee3115246f89132c4190e2e537c",
            "80092b154f8d4347be68946896311e8c",
            "2af98ef7ea9249dcb065fb3a13b1314a",
            "b612755e8cfd40faa86cbf937f3b7de0"
          ]
        },
        "id": "aaYXH3hZoNNy",
        "outputId": "bf754a70-4afa-4714-b2be-55f8f16f3bc1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "473d6eb0b1c74041aa6dcd0e23ec93c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec1958b31b9e48dfb41ef49f18d2f6af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "179a4d781b6647a7ae80f0bfd3a9641e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(1, 26), dtype=int32, numpy=\n",
            "array([[  101,  2338,  1037, 13090,  2050,  2008,  4240, 29177, 24137,\n",
            "         5562,  2306,  3788,  3292,  1999,  2821,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]],\n",
            "      dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1, 26), dtype=int32, numpy=\n",
            "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 26), dtype=int32, numpy=\n",
            "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0]], dtype=int32)>}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "240it [00:00, 669.69it/s]\n",
            "60it [00:00, 522.22it/s]\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "classes = train.intent.unique().tolist()\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_input = tokenizer('book a taverna that serves vichyssoise within walking distance in oh',padding='max_length', max_length = 26, truncation=True, return_tensors=\"tf\")\n",
        "print(bert_input)\n",
        "# print(bert_input.shape)\n",
        "def _prepare(df):\n",
        "    x, y = [], []\n",
        "    \n",
        "    for _, row in tqdm(df.iterrows()):\n",
        "      dic={}\n",
        "      text, label = row['text'], row['intent']\n",
        "      bert_input = tokenizer(text,padding='max_length', max_length = 26, truncation=False, return_tensors=\"pt\")\n",
        "      # temp=bert_input['input_ids']\n",
        "      # print(temp)\n",
        "      dic['input_ids']=bert_input['input_ids']\n",
        "      dic['mask']=bert_input['attention_mask']\n",
        "      x.append(dic)\n",
        "      y.append(classes.index(label))\n",
        "    return np.array(x), np.array(y)\n",
        "((train_x,train_y), (valid_x,valid_y)) =map(_prepare, [train, valid])\n",
        "train_y,valid_y=torch.from_numpy(train_y),torch.from_numpy(valid_y)\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b44CA6k-cAV5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ujmt5osqOS_",
        "outputId": "a94a1899-6ec8-47b1-e1c7-8c08e1b59911"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([240])\n",
            "torch.Size([60, 1])\n"
          ]
        }
      ],
      "source": [
        "print(train_y.shape)\n",
        "train_y=train_y.view(train.shape[0],1)\n",
        "valid_y=valid_y.view(valid.shape[0],1)\n",
        "print(valid_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsStlG03d_Ke"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w9lx47aMXsJ",
        "outputId": "c07297f0-c34c-49d3-9523-7099e14bb4e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "train_y[9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsEx-hJ2NVMA",
        "outputId": "4c71793f-452f-432e-a2f1-a67e061f9d22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PlayMusic',\n",
              " 'AddToPlaylist',\n",
              " 'RateBook',\n",
              " 'SearchScreeningEvent',\n",
              " 'BookRestaurant',\n",
              " 'GetWeather',\n",
              " 'SearchCreativeWork']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "6b732a00daf84e2c858f6211eae1a3f4",
            "4fade0f7cb0444d7b648bc58a39240ef",
            "163f5cc329094f33ba162039b1934b38",
            "bbd67b865cd54b9e8ca1fd08b926ab98",
            "a656f04ae67944e6afb02ca5452461b1",
            "6ed857289f4e492eb12139c51d612f43",
            "d0af96a54165416b9813c2f6d4995382",
            "27f5af0a236549f69448427d4586f6a5",
            "2815b6ca4bdc497fb4692557285faf39",
            "96570373118e49d7993473712cec119d",
            "f8d79b4cc7364f60939aae424e9aede5"
          ]
        },
        "id": "INjCxDbuu30x",
        "outputId": "884e92af-1e64-4a73-9881-45af39b44c6c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b732a00daf84e2c858f6211eae1a3f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        " bert1=BertModel.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njBokU-9D-Z4",
        "outputId": "bede7799-98d5-47a4-a5bc-9db92abe7c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 768)\n",
            "    (token_type_embeddings): Embedding(2, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (3): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (4): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (5): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (6): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (7): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (8): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (9): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (10): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (11): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(bert1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2pBjBNp9l-p",
        "outputId": "62c55787-7633-4145-c19a-1c18a7a5f844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101,  2377,  2070, 26232, 10882, 15000,  2361, 11332, 14604,  2860,\n",
            "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0]])\n",
            "tensor([[-0.7575, -0.3922, -0.8609,  0.6465,  0.3521, -0.1217,  0.5480,  0.3138,\n",
            "         -0.6562, -1.0000,  0.1510,  0.7787,  0.9587,  0.6255,  0.7540, -0.3826,\n",
            "          0.1961, -0.4454,  0.4272, -0.0617,  0.6428,  1.0000,  0.0835,  0.2724,\n",
            "          0.4108,  0.9156, -0.5536,  0.7615,  0.9002,  0.7406, -0.3686,  0.2016,\n",
            "         -0.9745, -0.3379, -0.9461, -0.9825,  0.2256, -0.5059, -0.1613, -0.0281,\n",
            "         -0.7191,  0.3251,  0.9999,  0.4439,  0.1762, -0.1728, -1.0000,  0.3187,\n",
            "         -0.6951,  0.7994,  0.6933,  0.7885,  0.1821,  0.4424,  0.3792, -0.1034,\n",
            "         -0.0760,  0.1015, -0.2641, -0.5908, -0.6294,  0.5734, -0.6729, -0.8165,\n",
            "          0.6100,  0.7568, -0.1674, -0.3708, -0.0597,  0.0239,  0.5576,  0.1827,\n",
            "         -0.1378, -0.8512,  0.4874,  0.3292, -0.6684,  1.0000, -0.1676, -0.9457,\n",
            "          0.8229,  0.6398,  0.4732, -0.2098,  0.7070, -1.0000,  0.4727, -0.0267,\n",
            "         -0.9763,  0.2977,  0.4007, -0.0193,  0.6972,  0.6481, -0.5918, -0.5005,\n",
            "         -0.2908, -0.7257, -0.4058, -0.4282,  0.1048, -0.2840, -0.2282, -0.1655,\n",
            "          0.3220, -0.4605, -0.2993,  0.6045, -0.1290,  0.6650,  0.4601, -0.4689,\n",
            "          0.3517, -0.8775,  0.5985, -0.3342, -0.9602, -0.6603, -0.9733,  0.6290,\n",
            "         -0.1804, -0.2878,  0.8535, -0.4617,  0.3047, -0.1309, -0.6100, -1.0000,\n",
            "         -0.5163, -0.5701, -0.2528, -0.2948, -0.9425, -0.9221,  0.5083,  0.8415,\n",
            "          0.0155,  0.9995, -0.3998,  0.9055, -0.0628, -0.5956,  0.3023, -0.5112,\n",
            "          0.7770, -0.2234, -0.3918,  0.1685, -0.2938,  0.0351, -0.6263, -0.1575,\n",
            "         -0.5011, -0.7456, -0.3673,  0.8792, -0.2312, -0.8021,  0.1349, -0.1316,\n",
            "         -0.3753,  0.7291,  0.5080,  0.3272, -0.4354,  0.4907,  0.4186,  0.4269,\n",
            "         -0.7843, -0.0251,  0.2367, -0.3324, -0.7997, -0.9616, -0.4016,  0.5010,\n",
            "          0.9625,  0.5229,  0.1880,  0.4851, -0.3420,  0.3022, -0.9245,  0.9567,\n",
            "         -0.2079,  0.2481, -0.6363,  0.5059, -0.6736,  0.3725,  0.6062, -0.2595,\n",
            "         -0.6861, -0.0469, -0.4513, -0.3707, -0.6600,  0.2362, -0.2024, -0.4656,\n",
            "         -0.2487,  0.7966,  0.7996,  0.2500,  0.2935,  0.5511, -0.7144, -0.3214,\n",
            "          0.1273,  0.2026,  0.1800,  0.9736, -0.6070,  0.0859, -0.8148, -0.9673,\n",
            "         -0.0106, -0.6263, -0.2010, -0.7156,  0.6916, -0.3022,  0.2010,  0.3931,\n",
            "         -0.7475, -0.7132,  0.2400, -0.4716,  0.4787, -0.3061,  0.9099,  0.9607,\n",
            "         -0.4973, -0.1739,  0.9097, -0.8007, -0.5994,  0.5283, -0.3197,  0.6926,\n",
            "         -0.6541,  0.9842,  0.8614,  0.5702, -0.8355, -0.6755, -0.1729, -0.5673,\n",
            "         -0.1191,  0.3277,  0.7235,  0.5849,  0.2773,  0.1194, -0.5793,  0.9030,\n",
            "         -0.9220, -0.9065, -0.5685, -0.1944, -0.9766,  0.6764,  0.3288,  0.5145,\n",
            "         -0.4509, -0.3701, -0.8771,  0.7160,  0.0915,  0.9251, -0.3499, -0.7291,\n",
            "         -0.5279, -0.8813, -0.0139, -0.2097, -0.1901, -0.0016, -0.8000,  0.5307,\n",
            "          0.3385,  0.4272, -0.7132,  0.9776,  1.0000,  0.9143,  0.7181,  0.4772,\n",
            "         -0.9996, -0.4690,  1.0000, -0.9516, -1.0000, -0.7242, -0.6259,  0.3195,\n",
            "         -1.0000, -0.1431, -0.1221, -0.7879,  0.5551,  0.9254,  0.9175, -1.0000,\n",
            "          0.6717,  0.7857, -0.6334,  0.6676, -0.5095,  0.9350,  0.3008,  0.4762,\n",
            "         -0.1856,  0.5441, -0.8973, -0.7255, -0.4760, -0.6179,  0.9967,  0.2080,\n",
            "         -0.7219, -0.7718,  0.3936, -0.1613,  0.0769, -0.8884, -0.2495, -0.1150,\n",
            "          0.6889,  0.1841,  0.2997, -0.4302,  0.0967,  0.3559,  0.2844,  0.6646,\n",
            "         -0.9331, -0.3640, -0.5801, -0.2211, -0.5078, -0.9262,  0.8740, -0.4353,\n",
            "          0.6413,  1.0000,  0.5172, -0.6943,  0.5858,  0.1587, -0.4983,  1.0000,\n",
            "          0.7772, -0.9478, -0.6057,  0.5102, -0.4724, -0.6176,  0.9989, -0.0815,\n",
            "         -0.5994,  0.1074,  0.9671, -0.9801,  0.9870, -0.7813, -0.9147,  0.8738,\n",
            "          0.8530, -0.1276, -0.6382,  0.2389, -0.7407,  0.2679, -0.6090,  0.5631,\n",
            "          0.4099, -0.1257,  0.8063, -0.4577, -0.5645,  0.3852, -0.4274, -0.0190,\n",
            "          0.8823,  0.4980, -0.2449,  0.1258, -0.3117, -0.7019, -0.8733,  0.4127,\n",
            "          1.0000, -0.1087,  0.7216, -0.2067, -0.0847, -0.0280,  0.4198,  0.4435,\n",
            "         -0.3631, -0.7937,  0.3601, -0.6661, -0.9805,  0.4428,  0.2552, -0.3473,\n",
            "          0.9999,  0.3116,  0.2931,  0.3365,  0.8964,  0.1359,  0.2726,  0.6114,\n",
            "          0.9296, -0.2611,  0.5825,  0.3523, -0.6499, -0.3439, -0.6365,  0.1143,\n",
            "         -0.8916, -0.0170, -0.8513,  0.8575,  0.8795,  0.4619,  0.3011,  0.4203,\n",
            "          1.0000, -0.7540,  0.4712,  0.5508,  0.5610, -0.9992, -0.4718, -0.4040,\n",
            "         -0.1235, -0.6692, -0.2688,  0.3193, -0.8925,  0.5056,  0.5895, -0.7973,\n",
            "         -0.9586, -0.4536,  0.3102, -0.0208, -0.9701, -0.6106, -0.4197,  0.2538,\n",
            "         -0.3107, -0.8190,  0.2769, -0.3630,  0.4946, -0.2460,  0.5954,  0.6312,\n",
            "          0.4318, -0.6632, -0.2034, -0.2325, -0.6485,  0.6539, -0.6030, -0.7427,\n",
            "         -0.2724,  1.0000, -0.5766,  0.8040,  0.5391,  0.3029, -0.2883,  0.2860,\n",
            "          0.9361,  0.2689, -0.7595, -0.4575,  0.5017, -0.4365,  0.5406,  0.1220,\n",
            "          0.7879,  0.6661,  0.5538,  0.1938,  0.0731,  0.2134,  0.9641, -0.2870,\n",
            "         -0.2985, -0.5105, -0.1810, -0.3099,  0.4212,  1.0000,  0.3889,  0.5098,\n",
            "         -0.9776, -0.5967, -0.7606,  1.0000,  0.7335, -0.6326,  0.6395,  0.6773,\n",
            "         -0.1158,  0.1105, -0.2216, -0.1012,  0.3221,  0.0919,  0.8897, -0.4858,\n",
            "         -0.9241, -0.5289,  0.4477, -0.8393,  0.9998, -0.5352, -0.2889, -0.2071,\n",
            "         -0.0682, -0.4879,  0.0622, -0.9248, -0.2170,  0.0294,  0.9055,  0.2720,\n",
            "         -0.5946, -0.7399,  0.7168,  0.3981, -0.5474, -0.8796,  0.9139, -0.9179,\n",
            "          0.4255,  1.0000,  0.3221, -0.0535,  0.0591, -0.3475,  0.3586, -0.2133,\n",
            "          0.4424, -0.8448, -0.2994, -0.3175,  0.4004, -0.2041, -0.5469,  0.3846,\n",
            "          0.2630, -0.5133, -0.6119, -0.0622,  0.3523,  0.7842, -0.3395, -0.0707,\n",
            "          0.0802, -0.0252, -0.8365, -0.3523, -0.4323, -1.0000,  0.4430, -1.0000,\n",
            "          0.4431,  0.3171, -0.2862,  0.6197,  0.3325,  0.3257, -0.3621, -0.5633,\n",
            "          0.3779,  0.6505, -0.2779, -0.2445, -0.5845,  0.4115, -0.1461,  0.2283,\n",
            "         -0.6954,  0.6548, -0.2329,  1.0000,  0.0961, -0.3837, -0.7576,  0.3335,\n",
            "         -0.3152,  1.0000, -0.3837, -0.8802,  0.3744, -0.6073, -0.7559,  0.3064,\n",
            "         -0.0772, -0.6763, -0.8234,  0.7960,  0.4105, -0.5880,  0.5215, -0.3478,\n",
            "         -0.4009,  0.2016,  0.7700,  0.9690,  0.4198,  0.4121, -0.5049, -0.3292,\n",
            "          0.8769,  0.3081, -0.0440,  0.2623,  1.0000,  0.3039, -0.8618, -0.0430,\n",
            "         -0.8586, -0.2736, -0.8424,  0.2360,  0.2382,  0.7826, -0.3064,  0.9304,\n",
            "         -0.4527,  0.1143, -0.3212, -0.4228,  0.2817, -0.7532, -0.9642, -0.9671,\n",
            "          0.5367, -0.3914, -0.1379,  0.3113,  0.2072,  0.3094,  0.3733, -1.0000,\n",
            "          0.8300,  0.5091,  0.8221,  0.9131,  0.5365,  0.4841,  0.2878, -0.9523,\n",
            "         -0.7239, -0.3455, -0.2829,  0.7097,  0.5500,  0.6240,  0.3482, -0.4380,\n",
            "         -0.3691, -0.5407, -0.7833, -0.9791,  0.5046, -0.3736, -0.6986,  0.9219,\n",
            "         -0.1844, -0.1842, -0.2450, -0.7350,  0.5507,  0.7023,  0.2615, -0.0420,\n",
            "          0.5217,  0.7324,  0.7968,  0.9723, -0.7667,  0.3185, -0.5463,  0.3978,\n",
            "          0.7452, -0.9069,  0.1786,  0.2107, -0.3977,  0.3567, -0.3154, -0.8317,\n",
            "          0.6372, -0.2691,  0.5582, -0.3607,  0.0352, -0.4467, -0.1807, -0.6271,\n",
            "         -0.5570,  0.6141,  0.0996,  0.7012,  0.7126, -0.0337, -0.5589, -0.2678,\n",
            "         -0.7571, -0.8393,  0.4657, -0.1303, -0.4948,  0.5326, -0.1156,  0.8026,\n",
            "          0.1496, -0.3761, -0.2627, -0.5225,  0.7500, -0.0617, -0.4891, -0.4680,\n",
            "          0.6148,  0.2847,  1.0000, -0.6259, -0.6669, -0.2770, -0.3087,  0.3930,\n",
            "         -0.3326, -1.0000,  0.4447, -0.4681,  0.6992, -0.2531,  0.6969, -0.4076,\n",
            "         -0.8607, -0.2552,  0.4227,  0.5186, -0.4572, -0.6026,  0.5825, -0.3806,\n",
            "          0.8237,  0.6587,  0.1806,  0.0448,  0.6225, -0.4721, -0.6403,  0.6751]],\n",
            "       grad_fn=<TanhBackward0>)\n"
          ]
        }
      ],
      "source": [
        "c=\"play some seventies filipp kirkorow\"\n",
        "bert_input = tokenizer(c,padding='max_length', max_length = 26, truncation=False, return_tensors=\"pt\")\n",
        "input_id=bert_input['input_ids']\n",
        "# input_id=input_id.numpy()\n",
        "print(input_id)\n",
        "r=bert1(input_id)['pooler_output']\n",
        "# r=r.numpy()\n",
        "# r=r[:,0,:]\n",
        "print(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0gEeBvYnZAk"
      },
      "outputs": [],
      "source": [
        "# from bert.tokenization.bert_tokenization import FullTokenizer\n",
        "# btokenizer = FullTokenizer(vocab_file=os.path.join(bert_ckpt_dir, \"vocab.txt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oN1-PfTSGv7",
        "outputId": "40cefc72-bee9-43c0-feb0-1d9135713d3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding(30522, 768, padding_idx=0)\n"
          ]
        }
      ],
      "source": [
        "embedding=bert1.embeddings.word_embeddings\n",
        "# tokenizer.pad_token_id\n",
        "print(embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBkIWDvpXuQW",
        "outputId": "eb55e809-4994-4983-dbc6-c1428cf74a19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PlayMusic', 'AddToPlaylist', 'RateBook', 'SearchScreeningEvent', 'BookRestaurant', 'GetWeather', 'SearchCreativeWork']\n"
          ]
        }
      ],
      "source": [
        "classes = train.intent.unique().tolist()\n",
        "print(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJ4yB17jmRe7"
      },
      "outputs": [],
      "source": [
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNet,self).__init__()\n",
        "    \n",
        "    self.bert = bert1\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "    self.linear = nn.Linear(768, 768)\n",
        "    self.tanh = nn.Tanh()\n",
        "    self.dropout1 = nn.Dropout(0.5)\n",
        "    self.linear2 = nn.Linear(768,7)\n",
        "    self.softmax =nn.Softmax(dim=1)\n",
        "    # self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self,x,mask=None):\n",
        "    _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "    dropout_output = self.dropout(pooled_output)\n",
        "    linear_output = self.linear(dropout_output)\n",
        "    tanh_layer = self.tanh(linear_output)\n",
        "    dropout2 = self.dropout(pooled_output)\n",
        "    linear2 = self.linear2(dropout2)\n",
        "    final_layer = self.softmax(linear2)\n",
        "    return final_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KB6wXNyAtsrP"
      },
      "outputs": [],
      "source": [
        "intent_model = NeuralNet()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optim = optimizor.Adam(intent_model.parameters(), lr=1e-6)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "intent_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyMYjFHsnPUY",
        "outputId": "9a0b0159-3aad-476d-a4c1-1d6b603ea814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNet(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (tanh): Tanh()\n",
              "  (dropout1): Dropout(p=0.5, inplace=False)\n",
              "  (linear2): Linear(in_features=768, out_features=7, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tc3ta2KjyP54"
      },
      "outputs": [],
      "source": [
        "train_loss_arr=[]\n",
        "val_loss_arr=[]\n",
        "epochs=10# LR=0.001\n",
        "count=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "id": "YdCv-Codt0O2",
        "outputId": "96889525-4aaf-44e1-eb6e-151dada28bfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss:  1.945                 | Train Accuracy:  0.142                 | Val Loss:  1.944                 | Val Accuracy:  0.183\n",
            "Epochs: 2 | Train Loss:  1.924                 | Train Accuracy:  0.246                 | Val Loss:  1.928                 | Val Accuracy:  0.233\n",
            "Epochs: 3 | Train Loss:  1.887                 | Train Accuracy:  0.383                 | Val Loss:  1.884                 | Val Accuracy:  0.383\n",
            "Epochs: 4 | Train Loss:  1.855                 | Train Accuracy:  0.492                 | Val Loss:  1.860                 | Val Accuracy:  0.433\n",
            "Epochs: 5 | Train Loss:  1.806                 | Train Accuracy:  0.583                 | Val Loss:  1.834                 | Val Accuracy:  0.417\n",
            "Epochs: 6 | Train Loss:  1.767                 | Train Accuracy:  0.621                 | Val Loss:  1.816                 | Val Accuracy:  0.500\n",
            "Epochs: 7 | Train Loss:  1.720                 | Train Accuracy:  0.671                 | Val Loss:  1.770                 | Val Accuracy:  0.583\n",
            "Epochs: 8 | Train Loss:  1.685                 | Train Accuracy:  0.696                 | Val Loss:  1.720                 | Val Accuracy:  0.617\n",
            "Epochs: 9 | Train Loss:  1.639                 | Train Accuracy:  0.775                 | Val Loss:  1.706                 | Val Accuracy:  0.617\n",
            "Epochs: 10 | Train Loss:  1.610                 | Train Accuracy:  0.775                 | Val Loss:  1.667                 | Val Accuracy:  0.683\n",
            "Epochs: 11 | Train Loss:  1.580                 | Train Accuracy:  0.787                 | Val Loss:  1.642                 | Val Accuracy:  0.683\n",
            "Epochs: 12 | Train Loss:  1.532                 | Train Accuracy:  0.846                 | Val Loss:  1.629                 | Val Accuracy:  0.650\n",
            "Epochs: 13 | Train Loss:  1.498                 | Train Accuracy:  0.921                 | Val Loss:  1.603                 | Val Accuracy:  0.733\n",
            "Epochs: 14 | Train Loss:  1.458                 | Train Accuracy:  0.938                 | Val Loss:  1.548                 | Val Accuracy:  0.833\n",
            "Epochs: 15 | Train Loss:  1.430                 | Train Accuracy:  0.963                 | Val Loss:  1.524                 | Val Accuracy:  0.867\n",
            "Epochs: 16 | Train Loss:  1.391                 | Train Accuracy:  0.979                 | Val Loss:  1.494                 | Val Accuracy:  0.883\n",
            "Epochs: 17 | Train Loss:  1.352                 | Train Accuracy:  0.988                 | Val Loss:  1.456                 | Val Accuracy:  0.900\n",
            "Epochs: 18 | Train Loss:  1.332                 | Train Accuracy:  0.992                 | Val Loss:  1.428                 | Val Accuracy:  0.917\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-54cc9c5ffda3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0minput_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintent_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0;31m# print(train_label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-102caffa55ed>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mdropout_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mlinear_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m         )\n\u001b[1;32m   1008\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m                 )\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m         )\n\u001b[1;32m    516\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2926\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2928\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optim = optimizor.Adam(intent_model.parameters(), lr=1e-6)\n",
        "for epoch_num in range(epochs):\n",
        "\n",
        "            total_acc_train = 0\n",
        "            total_loss_train = 0\n",
        "\n",
        "            for train_input, train_label in zip(train_x,train_y):\n",
        "                \n",
        "                train_label = train_label\n",
        "                mask = train_input['mask']\n",
        "                input_id = train_input['input_ids'].squeeze(1)\n",
        "                output = intent_model.forward(input_id,mask)\n",
        "                # print(train_label)\n",
        "                batch_loss = loss_fn(output, train_label)\n",
        "                total_loss_train += batch_loss.item()\n",
        "                \n",
        "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "                total_acc_train += acc\n",
        "\n",
        "                intent_model.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                optim.step()\n",
        "            \n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                for val_input, val_label in zip(valid_x,valid_y):\n",
        "\n",
        "                    val_label = val_label\n",
        "                    mask = val_input['mask']\n",
        "                    input_id = val_input['input_ids'].squeeze(1)\n",
        "\n",
        "                    output = intent_model.forward(input_id,mask)\n",
        "\n",
        "                    batch_loss = loss_fn(output, val_label)\n",
        "                    total_loss_val += batch_loss.item()\n",
        "                    \n",
        "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "                    total_acc_val += acc\n",
        "            \n",
        "            train_loss_arr.append(total_loss_train/len(train_x))\n",
        "            val_loss_arr.append(total_loss_val / len(valid_x))\n",
        "            print(\n",
        "                \n",
        "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_x): .3f} \\\n",
        "                | Train Accuracy: {total_acc_train / len(train_x): .3f} \\\n",
        "                | Val Loss: {total_loss_val / len(valid_x): .3f} \\\n",
        "                | Val Accuracy: {total_acc_val / len(valid_x): .3f}')\n",
        "                  \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_loss_arr=[1,2,3,4,5,6,7,4,3,2]\n",
        "# val_loss_arr=  [1,3,5,3,6,7,8,1,3,3]"
      ],
      "metadata": {
        "id": "4VYMujcx8_UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(np.linspace(1, 18, 18).astype(int), train_loss_arr,val_loss_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "xrlSvxrp5jzQ",
        "outputId": "d9ec7d82-ea62-4d83-ab2d-99f04cb57dd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7397ac1410>,\n",
              " <matplotlib.lines.Line2D at 0x7f7397ac1650>]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3ddXwVV/rH8c8ThQQNBE1IcPdgQQrFKYuUYkUqFJpite223fp2260XSoViVaC4lFKkSHEJHtwdEjSBALHz+2PCb1kag1zLzfN+vfIiuTN3zrOzt99Mzpw5R4wxKKWUyvk8nF2AUkop29BAV0opN6GBrpRSbkIDXSml3IQGulJKuQkvZzVctGhRExoa6qzmlVIqR9qyZcsFY0xgWtucFuihoaFERkY6q3mllMqRROR4etu0y0UppdyEBrpSSrkJDXSllHITGuhKKeUmNNCVUspNaKArpZSb0EBXSik3kfMCPfEmXIvJ1iH2n4tj1B8HOB9700ZFKaWU8+W8QD+8DD6pCJM6wLoxcPHwPR9i/eELjF52kPAPljN08hbWHb6AzguvlMrpxFlBFhYWZu7rSdFLR2HHL7DvNzi/y3otsCpU6QRVHoKSdcEj899Txy9eZ8rGE0yLPMmV+ETKB/rTv3EID9cLomBe73uvSymlHEBEthhjwtLcluMC/U6Xj8P+hVa4H18HJhnyl4LKHa1wD20OXj4ZHuJmYjK/7TzLTxuOs/3kFfJ6e9Ktbin6Nw6heqmC2atPKaVszH0D/U7xl+DAYti3AA4vh8R48C0AFdtZV+8V2kKeAhkeYtepq/y84TjzdpzmZmIK9coUYkCTEDrWKEkeb0/b1aqUUvcpdwT6nRJvwJGV1pX7/t8h/gJ4eEPZFtaVe+VOUKBkum+/Gp/IzK2nmLzhOEcuXCfA34deYcH0a1SG4AA/+9SslFJZkPsC/U4pyXByE+z/DfYugMtHrddDmkLXryCgbLpvNcaw7vBFflx/jKV7zmOAVpWL0b9xGR6oVAxPD7F//UopdYfcHeh3MgZi9lndMuu+BA9P6P0zhIRn+tazV28wdeMJpm4+SUzcLYIK5+Xx8FAeDw/FyzPnDRZSSuVMGuhpuXAIpva2bqz+bTTU7ZeltyUkpbBkzzl+Wn+cjUcvUbdMIUb1rkNIEX87F6yUUhkHeu69tCxaAZ76w7o6nzcUlr5pdc9kwsfLg861SjHt6SaM7lOHQ9HX6Dh6NdM3n9Sx7Eopp8q9gQ6QtzD0nwVhg2DtaJjWH25dy/Lbu9YpzaLnWlArqCD/mLWTiJ+3cOl6gh0LVkqp9OXuQAfw9IbOn0HHj+HAIpjUHq6czPLbSxfKy5SnGvPPTlVYvi+a9qNWsXJ/tB0LVkqptGmg39ZoCPSbCVdOwPhW1siYLPLwEIa0KM+8Yc0o7OfN499t5q15UdxMzLwLRymlbCXTQBeRSSISLSJR6WwvLCJzRGSniGwSkRq2L9NBKrS2+tV9/OH7zrBz+j29vVqpAswf3ownm5blh/XH6TxmDVGnr9qpWKWU+l9ZuUL/HuiQwfZ/AtuNMbWAgcBoG9TlPIGVYfAKCGoAswfDsnchJSXLb8/j7cmbf6vGT4MaEnczke5fr+WblYdJTtEbpkop+8o00I0xq4BLGexSDVieuu8+IFREitumPCfxC4ABc6DuAFj9Ccx4DBKu39MhmlcMZNGzLWhbrTgfLtpH3/EbOHU53k4FK6WUbfrQdwAPA4hIQyAECEprRxEZIiKRIhIZE5O9Oc3tzssHuoyBdu/B3l/hu44Qe+aeDlHY34evHq3Hpz1rs+dMLB1HrWbuttN2KlgpldvZItA/AAqJyHZgBLANSPNuoDFmnDEmzBgTFhgYaIOm7UwEwodD31+sedfHtYLTW+/xEEKP+kH8/mxzKpfIz3PTtjNy6jauxifaqWilVG6V7UA3xsQaY54wxtTB6kMPBI5kuzJXUrkDDFoCnj7WlXrU7Hs+RHCAH9OebsJL7SuzcNdZOo5exbrDF+xQrFIqt8p2oItIIRG5Pen4U8AqY0xsdo/rcopXh8HLoWRtmPkErPzQmhvmHnh6CMNaVWD20HDyeHvSb8JG/r1gD/EJSXYqWimVm2Rl2OJUYD1QWUROicggEYkQkYjUXaoCUSKyH+gIPGu/cp0sXyA89ivU7gsr37eeLI3Zf8+HqRVUiAUjm9GvURkmrDlK289WsXTPeTsUrJTKTXLv5FzZYYw1VcDK/0DSTajYHsJHQGgzq9/9HkQeu8Rrc6LYfz6ONlWL83aXagQV1jnXlVJp09kW7eX6Bdg8ETaNsxbRKFkbmoyA6t2sKQWyKDE5he/WHuXzpQcBeK5NRZ5sVhZvnZZXKXUXDXR7S7wBO6fB+q/gwgEoEASNI6DeQMiT9XVJT1+5wTvzd7Nkz3kqF8/Pe91rEBYaYMfClVI5jQa6o6SkwKGlsG4MHFsNPvmh/mPQKAIKBWf5MEv3nOft+bs5feUGvcOCeaVjFQr7Z7zYtVIqd9BAd4Yz22H9l/8d4li9uzWmvVTdLL09PiGJL5YdYsLqI+TP48WrnarSs34Qco999Eop96KB7kxXTsLGsbDlB0iIg5Bm1g3Uiu3AI/M+8v3n4nh97i42H7tMw9AA/t29BpWK53dA4UopV6SB7gpuxsLWH2HDNxB7CopUhCbDoHYf8M6b4VtTUgwzt5zi/d/3cu1mEk81L8fI1hXw8/FyUPFKKVehge5KkhNhzzxY9wWc3QH+gRA+EhoMsqbtzcCl6wl88PtepkeeonShvPyra3VaV83Z86Appe6NBrorMgaOrbFmczyyEvyKWF0xDQaDb74M37rp6CVen7uLA+ev0a5acd7uUp1ShTK+yldKuQcNdFd3YiOs+ggO/QF5A6yumIZDIE+BdN+SkJTCxDVHGb3sAH4+Xnz/RANqBRVyYNFKKWfQQM8pTkXCnx/BwcWQp9B/gz1v+kF9JOYaj323iUvXEvh2QBjNKhZ1YMFKKUfLKND1UURXEhQG/abDkJUQEg4r3oNRtWDF+3DjcppvKReYj1kR4QQH+PHE95v4bedZh5aslHIdGuiuqFRd6DsVnl4FZZvDnx/C5zWt5fDi/7p4VLECeZg2pAm1gwoxfOpWft5w3AlFK6WcTQPdlZWsDX0mQ8RaawHr1Z/CqJrwx9vWPDJ3KOjnzU+DGtGqcjFenxvFF8sO4qzuNKWUc2ig5wQlakCvH2DoeqjUHtaMsrpilrwB16L/f7e8Pp58O6A+D9crzWdLD/D2/N2k6OLUSuUaelM0J4rZD6s+gaiZ4OkLdR6FWr0huCGIkJJi+M/vexm/+ihdapfik5618fHS391KuQMd5eKuLhyyumF2z7bmZS9UBmr0gJo9McWqMfbPI3y4aB8tKgUytn89fbJUKTegge7ubsbC/oWwawYcXgEmGQKrQs1HWGDCGbnoMrWCCvHd4w101kalcjgN9Nzk+gXYPQd2zYSTGwC4ElCHMTF12FGwFV881V6fKlUqB9NAz62unICoWbBrFpzfRbIRtnjUIqTlYxRv9Mg9Lb6hlHINGugKovcSvW4yCdunE8R5Ujx98ajUDmo8Yo2cyWTGR6WUa9AnRRUUq0qxbv8madhWnvb9kJ+THiTh6HqY8Rh8XBGW/9tacUkplWNpoOcyoYH5eHfY40wpPJSacaNZ32yS9dDSqo9h1pOQeNPZJSql7pMGei50e6qAmkEBPLosDz8FvwNt37Vupv78cJrTCyilXF+mgS4ik0QkWkSi0tleUER+FZEdIrJbRJ6wfZnK1m5PFfBg5WK8MW83H19rR8rDE+HUZpjUwbqhqpTKUbJyhf490CGD7cOAPcaY2kBL4FMR0cHOOUBeH0/GDqhP77BgvlpxmAGbgrjSYxrEnYMJbawVlZRSOUamgW6MWQVk9De4AfKLtRx9vtR9k2xTnrI3b08PPuhRk4961CLy2GXazUlhZ/tp4OEN33WCQ8ucXaJSKots0Yf+JVAVOAPsAp41xqQ5XEJEhohIpIhExsTE2KBpZQsiQq8GwcwZ2hR/Xy+6z7zMj9UnYAqHwJResG2ys0tUSmWBLQK9PbAdKAXUAb4UkTTXTjPGjDPGhBljwgIDA23QtLKlaqUKMH94UzpUL8GbKy4x3Pd9EoObwryh1kpKOh2vUi7NFoH+BDDbWA4BR4EqNjiucoL8ebz58tG6vNOlOksOx9Pm3DAuVehhrZ7060hI1t40pVyVLQL9BNAaQESKA5WBIzY4rnISEeGx8FBmRoSTJN402tuD7WUHw9Yf4Ze+cOuas0tUSqUhK8MWpwLrgcoickpEBolIhIhEpO7yLhAuIruAZcDLxpgL6R1P5Ry1gwvx28hmtKhYjG57WzG52AuYQ3/A9w/9z8IaSinXoHO5qEylpBjGrz7CR4v30yt/FO8lf4ZHvmLQfxYUrejs8pTKVXQuF5UtHh7C0w+UZ+rgxiw39eh583VuxsdhJraFExudXZ5SKpUGusqyhmUD+G1kc/KGNqBt3BvEJPtjfuwCe+Y7uzSlFBro6h4VzefLD082pEfrZnSIe509JhQzfSBsGOvs0pTK9TTQ1T3z9BCea1OJ0U+2YbB5gz9MGCx6GZa+qWPVlXIiDXR135pXDGT2s22YUOItfkxqC2tHk7LgBZ1XXSkn0UBX2VKiYB4mD2nKsYbv8FVSFzy2TCJ59hBITnR2aUrlOhroKtu8PD14s0t1fNu/w4eJffCMmkHi1AG6WIZSDqaBrmzmqeblqNrrLd5OfhLvQ79z86eekHDd2WUplWtooCub6lK7FO0ef41/mmF4n1hD/MQucOOKs8tSKlfQQFc2F16+KAMiXuGfXi/ifX4b18d1hGs6XbJS9qaBruyiaskCjBz+Im/4vYHHpUNcG9sWrp52dllKuTUNdGU3pQvl5ZXhw3gv4D1S4s4R901ruKQTcSplLxroyq4K+fnw+tBBjAn+jMQbccR905aUc3ucXZZSbkkDXdldHm9PXnmyLz9XHUt8QhI3xrUn8cQWZ5ellNvRQFcO4ekhjOjdmSWNfuBSki9J33Um/sCfzi5LKbeiga4cRkQY0KklO9pN43RKITynPMKVHQudXZZSbkMDXTlc52b1Of/wbA6bUvjPGcDZ9b84uySl3IIGunKKprWrYgb+ym4qUGxxBMf+GOfskpTK8TTQldNUL1+GgIgFbPWoReial9g372Nnl6RUjqaBrpyqTIlAyo5cwAafJlTZ9m9OjO5A8tovIXqvzq2u1D3SRaKVS4i/eZOV416k8oVllPc4a72YvySUawnlH7T+zVfMeQUq5SIyWiRaA125DGMMC3ae5Zt5K6mTsI0nSh6lwrUtyI1L1g7Fa0L5llbAl2kC3nmdWq9SzqCBrnKUC9du8da83fy26yy1SuVndCsPyl7ZCIdXwIkNkJIInr4Q0iT16r0VFK8BHtqDqNxftgJdRCYBnYFoY0yNNLa/BPRL/dELqAoEGmMuZXRcDXSVmYW7zvLG3ChibyYy4sGKPNOyPN7JN+D4OivcDy+HmL3Wzv6B/+2eqdYVfPydWbpSdpPdQG8BXAN+TCvQ79r3b8DzxpgHMytKA11lxaXrCbw1fze/7jhD9VIF+PiR2lQrVeC/O8SegSMrrYA/sgKux0DRytDzeyhezVllK2U32e5yEZFQYEEWAn0KsMIYMz6zY2qgq3uxKOocr8+N4kp8AsNaVWBYqwr4eN3VxZKSAoeXwdyhcCsOOn0EdQeAiHOKVsoOMgp0m3U6iogf0AGYlcE+Q0QkUkQiY2J0wQOVdR1qlGDp8y34W+1SjF52kC5friHq9NX/3cnDAyq2hYg1ENwA5o+A2UOscFcqF7DlXaS/AWsz6js3xowzxoQZY8ICAwNt2LTKDQr7+/B57zpMGBjGpesJdP1qLZ8s3s+tpOT/3TF/cRgwF1r+E6JmwriWcG6XU2pWypFsGeh9gKk2PJ5SaWpTrThLn3+A7nVL8+WKQ/xtzBp2nLxr3VIPT2j5MgycD7euwfjWEDlJH1ZSbs0mgS4iBYEHgHm2OJ5SmSno580nPWvz3eMNiL2RRPev1/LB7/u4mXjX1XrZ5lYXTGhTWPA8zHwSbsY6p2il7CzTQBeRqcB6oLKInBKRQSISISIRd+zWHVhijLlur0KVSkurKsVY8kILetYPZuyfh3noi9XsPXtXYOcLhH6z4ME3YM9cGPcAnNnunIKVsiN9sEi5jT8PxPCPmTu4fiuZbwfUp2mFon/d6fg6mDkI4i9Au/eg4WAdBaNyFIeMclHK2R6oFMjcYU0JKpyXx7/bxJxtp/66U0i41QVTriX8/hJMHwg3rvx1P6VyIA105VZKFszL9IgmhIUE8Py0HXy14hB/+SvUvwj0nQZt/wX7foNvW8BpXeNU5Xwa6MrtFMjjzQ9PNqRrnVJ8vHg/b8yLIjnlrlD38ICmz8KTiyAlGSa2hw3f6CgYlaNpoCu35OPlwee96hDxQHl+3nCCp3/awo2E5L/uGNwQIlZbDyQtegV+6QfxGU5DpJTL0kBXbsvDQ3ilYxX+1bU6y/adp+/4DVy8duuvO/oFQJ8p0P59OLjE6oKJmmVduSuVg2igK7c3sEkoY/vXZ+/ZWHp8s47jF9MYXSsCTYbBk4vB288ar/5lGGz5HpLS+CWglAvSQFe5QvvqJZgyuDFXbyTy8Nfr2H73k6W3BdWHoeuh14/gWwB+fRZG14Z1Y6wnTpVyYRroKteoH1KYWc+E4+frSd9xG1i293zaO3p4WnOqD1kJA+ZAkQqw5HX4vDqseF/72JXL0kBXuUq5wHzMfqYpFYrlY/CPkUzeeDz9nUWsBTMeXwBPLYOQpvDnh1awL3oVrp52XOFKZYEGusp1AvP78suQxjxQKZDX5kTxyeL9fx2rfregMOg7BYZugKpdYOO3VlfMvGFw4ZBjClcqExroKlfy9/Vi/MAw+jQI5ssVh3hxxg4SklIyf2OxqvDwtzByG9R/HHbNtG6eTh+o88Mop9O5XFSuZozhi2WH+PyPAzSvWJSv+9Ujfx7vrB/gWrT1QNLmCXAr1uqiaf6i1T2jc8QoO8j2EnT2oIGuXMn0yJO8OnsXlYvn57snGlC8QJ57O8DNq7B5Imz42lrXtHQYVHkIQptDqTrgeQ+/JJTKgAa6Ulmwcn80QydvpbCfD5/2qk3jckXu/SCJN2Dbz9ZiGtF7rNe8/aFMIwhtBiHNoFRd8PKxbfEq19BAVyqLok5f5emftnD6yg3aVivOqx2rUC4w3/0d7FoMHF9rfR1bc0fA+0FwI2vRjdDmUKqeBrzKMg10pe7BzcRkJq45yjcrD3MzMZn+jUMY2boiAf7ZDN3rF/8b7sfXwvko63WvvNacMqHNrZAvXR+8fLP/P0S5JQ10pe7DhWu3+HzpAaZuOoG/rxfDW1XgsfBQ8nh72qaB+EvWghvH1lhf56MAA155rIAv+wDUe8xacUmpVBroSmXDwfNxvL9wLyv2xxBUOC8vd6hC51olEVuPYom/BCfWw7G1cGw1nNtlhXuDQRA+EvIXt217KkfSQFfKBtYcvMC/f9vDvnNx1AkuxBudq1I/JMB+DV44CKs/hZ3TrVEy9Z+w5nAvUNJ+bSqXp4GulI0kpxhmbT3FJ4v3Ex13i041S/ByhyqEFPG3X6MXD8Oaz2DHLyCeUG8gNHsOCgbZr03lsjTQlbKx+IQkxq06wrd/HiEpJYXHmoQy4sGKFPSz43jzy8dg9WewfYr1c93+0Ox5KBxivzaVy9FAV8pOzsfe5NMl+5mx5RQF83oz8sGK9G8cgo+XHWfVuHIC1oyCbT+BSYHafa2nUwPK2q9N5TI00JWysz1nYnl/4V7WHLpAaBE/XulYhfbVS9j+xumdrp6GtaOtRThSkqB2HyvYi5S3X5vK6bIV6CIyCegMRBtjaqSzT0tgFOANXDDGPJBZURroyt0YY1i5P4b3Fu7lUPQ1GpYN4M3O1ahRuqB9G447ZwV75CRIToCaPaH53yGwkn3bVU6R3UBvAVwDfkwr0EWkELAO6GCMOSEixYwx0ZkVpYGu3FVScgpTN5/k86UHuByfQM/6Qfy9fWWK5b/H+WHuVdx5WD/GmlMm8QbUeBha/AOKVbFvu8qhst3lIiKhwIJ0An0oUMoY8/q9FKWBrtzd1RuJfLn8IN+vO4aPpwdDW1VgULOytnswKT3XL8D6L2HTeEi6aS2AXam9fdtUDpNRoNvizk0loLCIrBSRLSIy0AbHVCrHK5jXm9ceqsaS5x8gvEJRPl68nzaf/clvO89mvqBGdvgXhTZvw7M7oURNmDYAjq6yX3vKZdgi0L2A+sBDQHvgDRFJs/NORIaISKSIRMbExNigaaVcX9mi/owfGMbkpxqRz9eLYVO20uvb9ew6ddW+DfsXgf6zIaAcTOkDJzfbtz3ldLYI9FPAYmPMdWPMBWAVUDutHY0x44wxYcaYsMBAnZ9C5S5NKxTlt5HNeb97TY7EXKfLV2v4+4wdnI+9ab9G/QJg4Fxr2oDJPeDsTvu1pZzOFoE+D2gmIl4i4gc0Avba4LhKuR1PD+HRRmVY8VJLhrQox/ztZ2j1yUq+XH6Qm4nJ9mk0fwkYOA988sFP3SHmgH3aUU6XaaCLyFRgPVBZRE6JyCARiRCRCABjzF5gEbAT2ARMMMZE2bNopXK6Anm8ebVjVZa+0IIWFQP5ZMkBWn/6J7/uOGOf/vVCZWDgfGtZvB+7wuXjtm9DOZ0+WKSUC1h/+CLvLtjDnrOx1A8pzJudq1E7uJDtGzoXBd8/BHkLwROLdKKvHMjeo1yUUtnUpHwRfh3RjA971OT4xXi6frWWF6Zv59qtJNs2VKKGdaP0+gX4qZu16IZyGxroSrkITw+hd4MyrHypJc+0LM+87WfoM249MXG3bNtQUH14dJo12dfP3a0FrpVb0EBXysXk8/Xi5Q5VmDAwjMPR13lk7DqOX7xu20ZCm0Hvn+H8HpjcCxJsfHzlFBroSrmoVlWKMXlwI67eSKTHN+uIOm3jK+mKbaHHBDi1CX7pB4l2HD6pHEIDXSkXVq9MYWZGhOPr5Unvb9ez9tAF2zZQvRt0/QqOrICZT0Jyom2PrxxKA10pF1ehWD5mPRNOUGE/Hv9uE/N3nLFtA3UehU6fwP7fYO4zkGKn8fDK7jTQlcoBShTMw/SIJtQNLszIqdv4bu1R2zbQcDC0fgt2zYAFz4OThjOr7NFAVyqHKJjXmx8HNaR99eK88+sePly0z7YPITV/wVogY+sPsOR1DfUcyMvZBSilsi6Ptydf96vPG/Oi+GblYWLibvGfh2vi7Wmja7MH34Bb16zpd33zQ8tXbHNc5RAa6ErlMJ4ewnvdalAsvy+j/jjIxWu3+KpfPfx8bPCfswh0+AASrsHK/1jzv4QPz/5xlUNol4tSOZCI8FybSrzXvQZ/Hojh0fEbuXw9wTYH9/CALmOgWjdY8hpsHKfdLzmEBrpSOVi/RiF83a8+e87G0mPsOk5djrfNgT084eHxULE9/P4SfBMO2yZDko2fWlU2pYGuVA7XoUYJfnqyITFxt+jxzTr2nYu1zYG9fKDPZOj+LYgHzBsKo2rC6k/hxmXbtKFsSgNdKTfQqFwRZkQ0AaDn2PVsOnrJNgf29IbafSBiDQyYA8Wrw7J/wWfV4feXrflglMvQQFfKTVQpUYBZz4QTmN+X/hM3snj3OdsdXATKP2iFesRaqNYFNk+EL+rCjMfh1BbbtaXumwa6Um4kqLAfsyLCqV6qAM/8vIWfN9hhIYsSNaD7WHhuJ4SPhEPLYcKDMKkj7FsIKSm2b1NliS5woZQbik9IYviUbSzfF0376sV5t2sNihXIY5/GbsXB1p9gw9dw9SQUqQBNhltdNd557dNmLpbRAhca6Eq5qaTkFCauOcpnSw/g4+XB6w9VpVdYMCJinwaTk2DPXFg3Bs5uB7+i1pQCDZ4C/6L2aTMX0kBXKhc7euE6r8zaycajlwgvX4T/PFyTkCL+9mvQGDi+1gr2A4vAKw/UGwgPvAL+RezXbi6hga5ULpeSYpi6+QQfLNxHYkoKL7atzJPNyuLpYaer9dti9lvBvn0K+OaDlv+EBoOs0TPqvmigK6UAOHv1Bm/MjeKPvdHUDirIh4/UokqJAvZvOHovLHoFjqyEopWhw3+gQmv7t+uGdJFopRQAJQvmZfzAMMb0rcupyzfo/MUaPluyn1tJdp4DvVhVGDAX+kyF5AT4+WGY2hcuHrZvu7mMXqErlUtdvp7Auwv2MHvbaSoUy8eHPWpSPyTA/g0n3bJGxKz6xAr3xkOhxd+t2R1VpvQKXSn1F4X9ffisdx2+f6IBNxKSeWTset6ev5vrt5Ls27CXLzR7HkZsgZo9Ye0oGFPfmitGx7BnS6aBLiKTRCRaRKLS2d5SRK6KyPbUrzdtX6ZSyl5aVi7G4udbMLBxCD+sP0a7z1fx54EY+zecvwR0+xqeWg4Fg625Yia0hpOb7d+2m8rKFfr3QIdM9lltjKmT+vWv7JellHKkfL5evNO1BjMjmpDH24PHJm3ihenbbTclb0aC6sOgpdYkYLFnYGIbmD3E+l7dk0wD3RizCrDRTD9KKVdWPySA30Y2Z8SDFZi//QxtP/+T33aetX/DHh7Wk6UjtljL4O2eA2PCrH72xJv2b99N2KoPvYmI7BCR30Wkeno7icgQEYkUkciYGAf8SaeUumd5vD15sV1lfh3RjFKF8jJsylb+OWcXNxPtPBIGrLHqrd+EYZugfCtY/i581RD2/qqLbGRBlka5iEgosMAYUyONbQWAFGPMNRHpBIw2xlTM7Jg6ykUp15eUnMInSw4w9s/D1ChdgK8frU+ZIn6OK+DISlj0KkTvgfKtoetXUKCk49p3QXYd5WKMiTXGXEv9fiHgLSI6cYNSbsDL04NXOlZhwsAwTlyM56Exq1m657zjCijXEp5eDR0/guPrrJWT9i10XPs5TLYDXURKSOpsPyLSMPWYF7N7XKWU62hTrTi/jWxOaBF/Bv8YyX8W7iUx2UFDDD29oNHT8PQqKBgEv/SFBc9Dgo2W23MjWRm2OBVYD1QWkVMiMkhEIkQkInWXR4AoEdkBfAH0MeYQEREAAA2xSURBVM56WkkpZTfBAX7MfKYJAxqH8O2qIzw6fgPnYx14wzKwEjz1B4SPgMhJMO4BOLvDce3nAPqkqFLqns3bfppXZ+/Cz8eT0X3q0rSCg3tZD6+AOREQfxHavAWNh1kjZXIBfVJUKWVTXeuUZv7wphT282HAxI2MWXaQlBQHXhyWbwXPrIOK7WDJ69bcMLEOGF7p4jTQlVL3pUKx/Mwb3pQutUvx6dIDPPH9Zi454kGk2/yLQJ/J0HkUnNigN0zRQFdKZYOfjxef967De91rsP7wRTp/sZqtJy47rgARCHtCb5im0kBXSmWLiNCvUQizngnH01Po/e16vlt7FIfen/vLDdOWcHan49p3ERroSimbqBlUkAXDm/NApWK88+sehk/ZRtzNRMcV4OUL7f5tzbt+8yqMf9BaLSkXzeCoga6UspmCft6MH1ifVztWYdHuc3T5ci17z8Y6toi0bpjGnXNsDU6iga6UsikR4ekHyjN1cGOu30qi21drmbzxOMmOHAVz9w3Tr5vkihumGuhKKbtoWNaauTEstDCvzYmi0+jVLNt73nF962ndMJ3zDFw95Zj2nUAfLFJK2VVKimFh1Fk+WbyfYxfjaRBamJc7VCEs1AHL3d2WdAtW/gfWfwXiAQ2HWKsm+TmwBhvJ6MEiDXSllEMkJqcwPfIko/84SHTcLdpULcZL7atQuYQD1xK9cgJWvA87foE8BaDZC9Y8Md55HVdDNmmgK6Vcxo2EZCatPcrYPw9z7VYS3euW5oW2lQgq7MBpec9FwbJ/wcHFkL8UtHoVaj9qTQTm4jTQlVIu50p8At+sPMx3646Bgf6NQxjWqjxF8vk6rohja2DpW3A6EopWthbXqPKQ1f/uojTQlVIu6+zVG4xaepAZW07i5+PF4ObleKp5Wfx9HXS1bAzsWwB/vAMXD0JQQ2j7DoSEO6b9e6SBrpRyeYei4/hk8QEW7T5H0Xw+jHiwIn0blsHHy0GD8ZKTYPvPsPIDiDsLlTpA67egeDXHtJ9FGuhKqRxj24nLfLhoHxuOXCI4IC8vtq1Ml9ql8PBwUDdIQjxsHAtrRsGtWKjzKLR8FQoFO6b9TGigK6VyFGMMfx6I4aNF+9lzNpYqJfLzRudqjp13Pf4SrPkMNo6zfm44GJq/6PShjhroSqkcKSXF8OvOM3y65AAnLsUztGV5XmhbCS9PBz4TeeWkNYZ9+xTwLQAPvmYNdXQSXeBCKZUjeXgIXeuUZsnzLejbMJivVx7m0fEbOXfVgUvfFQqGbl9b88OEhFvdMC5Kr9CVUjnG3G2n+eecXeT19uTz3nVoUSnQ8UWkpDh1uTu9QldKuYVudUszf3gziubz5bHvNvHpkv2OnfQLXHrtUtetTCml0lChWD7mDmtKz/pBjFl+iH4TNhAd68AuGBemga6UynHy+njy0SO1+bRnbXacvEqnL1az9tAFZ5fldBroSqkcq0f9IOYPb0phPx/6T9zI50sPOL4LxoVkGugiMklEokUkKpP9GohIkog8YrvylFIqYxWL52fe8KZ0r1ua0csOMmDiRqLjcmcXTFau0L8HOmS0g4h4Ah8CS2xQk1JK3RM/Hy8+61WHjx6pxdYTl3noizWsO5z7umAyDXRjzCrgUia7jQBmAdG2KEoppe5Hr7Bg5g1rRoE8XvSfsJEvlh3MVV0w2e5DF5HSQHfgmyzsO0REIkUkMiYmJrtNK6XUX1QukZ/5w5vRpXYpPlt6gMe/28SFa7ecXZZD2OKm6CjgZWNMSmY7GmPGGWPCjDFhgYFOeCBAKZUr+Pt68XnvOnzwcE02Hb1Ep9Gr2XDkorPLsjtbBHoY8IuIHAMeAb4WkW42OK5SSt03EaFPwzLMHdaUfL5ePDp+A18ud+8umGwHujGmrDEm1BgTCswEhhpj5ma7MqWUsoGqJQswf0QzOtcqxSdLDlijYNz0QaSsDFucCqwHKovIKREZJCIRIhJh//KUUir78vl6MbpPHT7qYY2C6Th6NSv2u98YDp2cSymVqxyKjmP4lG3sOxfH4OZleal9FcetimQDOjmXUkqlqlAsP3OHNWVA4xDGrz7KI2PXcfzidWeXZRMa6EqpXCePtyfvdqvB2P71OXbhOg99sYZ52087u6xs00BXSuVaHWqUYOGzzalcIj/P/rKdf8zcQXxCkrPLum8a6EqpXC2osB/ThjRmeKsKzNhyir+NWcOeM667KlFGNNCVUrmel6cHf29fmcmDGhF3M4luX6/lp/XHcNagkfulga6UUqnCKxTl92ebE16+CG/M203Ez1u4Ep/g7LKyTANdKaXuUCSfL5Mea8DrD1Vl+b5oOo1ezeZjmc1P6Bo00JVS6i4eHsJTzcsx65lwvL086P3tesbkgJkbNdCVUiodtYIKsWBEM/5WuxSfLj1A/wkbOXkp3tllpUsDXSmlMpA/jzejetfh40dqsf3kFVp8vIIBEzcyb/tpbiYmO7u8/6GP/iulVBaduXKD6ZEnmRF5itNXblAgjxdd65SmV1gwNUoXQETsXkNGj/5roCul1D1KSTGsP3KR6ZEnWRR1jltJKVQpkZ9eYcF0q1uaAH8fu7Wtga6UUnZy9UYiv+44w4zIk+w4dRVvT6FN1eL0CgumecWieHnatmdbA10ppRxg37lYZkSeYu6201y8nkDxAr70qBdEz7Bgyhb1t0kbGuhKKeVACUkpLN8XzYzIk6zYH02KgYahAfQMC6JTzZL4+3rd97E10JVSykmiY28ye9tppkee5EjMdfx8PHmhbSWeal7uvo6XUaDf/68JpZRSmSpWIA8RD5Tn6Rbl2HriMtM3n6Jkwbx2aUsDXSmlHEBEqB8SQP2QALu1oQ8WKaWUm9BAV0opN6GBrpRSbkIDXSml3IQGulJKuQkNdKWUchMa6Eop5SY00JVSyk047dF/EYkBjt/n24sCF2xYjj3llFq1TtvLKbVqnbZl7zpDjDGBaW1wWqBnh4hEpjeXgavJKbVqnbaXU2rVOm3LmXVql4tSSrkJDXSllHITOTXQxzm7gHuQU2rVOm0vp9SqddqW0+rMkX3oSiml/iqnXqErpZS6iwa6Ukq5CZcOdBHpICL7ReSQiLySxnZfEZmWun2jiIQ6ocZgEVkhIntEZLeIPJvGPi1F5KqIbE/9etPRdd5RyzER2ZVax1/WABTLF6nndKeI1HNCjZXvOFfbRSRWRJ67ax+nnVMRmSQi0SISdcdrASKyVEQOpv5bOJ33Ppa6z0ERecwJdX4sIvtS/7+dIyKF0nlvhp8TB9T5toicvuP/307pvDfDjHBAndPuqPGYiGxP572OOZ/GGJf8AjyBw0A5wAfYAVS7a5+hwNjU7/sA05xQZ0mgXur3+YEDadTZEljg7HOaWssxoGgG2zsBvwMCNAY2usDn4BzWwxQucU6BFkA9IOqO1z4CXkn9/hXgwzTeFwAcSf23cOr3hR1cZzvAK/X7D9OqMyufEwfU+Tbw9yx8NjLMCHvXedf2T4E3nXk+XfkKvSFwyBhzxBiTAPwCdL1rn67AD6nfzwRai4g4sEaMMWeNMVtTv48D9gKlHVmDjXUFfjSWDUAhESnpxHpaA4eNMff7VLHNGWNWAZfuevnOz+IPQLc03toeWGqMuWSMuQwsBTo4sk5jzBJjTFLqjxuAIHu1n1XpnM+syEpG2ExGdabmTi9gqr3azwpXDvTSwMk7fj7FX4Py//dJ/ZBeBYo4pLo0pHb51AU2prG5iYjsEJHfRaS6Qwv7XwZYIiJbRGRIGtuzct4dqQ/p/0fiKucUoLgx5mzq9+eA4mns42rn9kmsv8bSktnnxBGGp3YNTUqnC8uVzmdz4Lwx5mA62x1yPl050HMUEckHzAKeM8bE3rV5K1aXQW1gDDDX0fXdoZkxph7QERgmIi2cWEuGRMQH6ALMSGOzK53T/2Gsv7FdejywiLwGJAGT09nF2Z+Tb4DyQB3gLFZ3hivrS8ZX5w45n64c6KeB4Dt+Dkp9Lc19RMQLKAhcdEh1dxARb6wwn2yMmX33dmNMrDHmWur3CwFvESnq4DJv13I69d9oYA7Wn613ysp5d5SOwFZjzPm7N7jSOU11/nbXVOq/0Wns4xLnVkQeBzoD/VJ/+fxFFj4ndmWMOW+MSTbGpADj02nfVc6nF/AwMC29fRx1Pl050DcDFUWkbOqVWh9g/l37zAdujxR4BFie3gfUXlL7ziYCe40xn6WzT4nbffsi0hDrvDvjF4+/iOS//T3WDbKou3abDwxMHe3SGLh6R1eCo6V71eMq5/QOd34WHwPmpbHPYqCdiBRO7UJol/qaw4hIB+AfQBdjTHw6+2Tlc2JXd9236Z5O+1nJCEdoA+wzxpxKa6NDz6e977pm5wtrxMUBrDvZr6W+9i+sDyNAHqw/xw8Bm4ByTqixGdaf1zuB7alfnYAIICJ1n+HAbqy78BuAcCedz3KpNexIref2Ob2zVgG+Sj3nu4AwJ9XqjxXQBe94zSXOKdYvmbNAIla/7SCsezfLgIPAH0BA6r5hwIQ73vtk6uf1EPCEE+o8hNXvfPuzenuUWClgYUafEwfX+VPq528nVkiXvLvO1J//khGOrDP19e9vfy7v2Ncp51Mf/VdKKTfhyl0uSiml7oEGulJKuQkNdKWUchMa6Eop5SY00JVSyk1ooCullJvQQFdKKTfxfxH/dAtzrrykAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAtcrmsMaezZ"
      },
      "outputs": [],
      "source": [
        "label2id={}\n",
        "id2label={}\n",
        "id=0\n",
        "for t in classes:\n",
        "  id2label[id]=t\n",
        "  label2id[t]=id\n",
        "  id+=1\n",
        "print(id2label)\n",
        "print(label2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvTqYNgYXxus"
      },
      "outputs": [],
      "source": [
        "torch.save(intent_model,\"/content/untitled\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nfxU5tqhv5y"
      },
      "outputs": [],
      "source": [
        "intent_model=torch.load(\"/content/untitled\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5KpMmwg5Qhf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85b6b2d8-21a6-44fc-8c15-b51cd86d1dd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "will it snow in mt on june 13 2038\n",
            "GetWeather\n",
            "on june 27 2026 i d like to go to a delaware gastropub\n",
            "BookRestaurant\n",
            "add garry shider album to my classical essentials\n",
            "AddToPlaylist\n"
          ]
        }
      ],
      "source": [
        "from numpy import argmax\n",
        "commands=[\"will it snow in mt on june 13 2038\",\"on june 27 2026 i d like to go to a delaware gastropub\",\"add garry shider album to my classical essentials\"]\n",
        "for command in commands:\n",
        "  print(command)\n",
        "  bert_input = tokenizer(command,padding='max_length', max_length = 26, truncation=True, return_tensors=\"pt\")\n",
        "  input_id=bert_input['input_ids']\n",
        "  mask=bert_input['attention_mask']\n",
        "  op_class=classes[argmax(intent_model(input_id,mask).detach().numpy()[0])]\n",
        "  print(op_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giV4_Ykma_Qe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c380b0ef-bbea-4199-98f5-e475f52e5d1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0343, 0.8178, 0.0447, 0.0360, 0.0218, 0.0288, 0.0167]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.0554, 0.7602, 0.0550, 0.0371, 0.0296, 0.0381, 0.0245]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(intent_model.forward(input_id,mask))\n",
        "ten=intent_model.forward(input_id,mask).detach().numpy()\n",
        "pt=torch.Tensor(ten)\n",
        "print(pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LP4uUquo60CX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9785271b-b8ce-4ddb-d438-a931f34ec5e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers_interpret\n",
            "  Downloading transformers-interpret-0.6.0.tar.gz (35 kB)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from transformers_interpret) (4.18.0)\n",
            "Collecting captum>=0.3.1\n",
            "  Downloading captum-0.5.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from captum>=0.3.1->transformers_interpret) (1.21.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from captum>=0.3.1->transformers_interpret) (3.2.2)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from captum>=0.3.1->transformers_interpret) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6->captum>=0.3.1->transformers_interpret) (3.10.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers_interpret) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers_interpret) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers_interpret) (4.11.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers_interpret) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers_interpret) (0.11.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers_interpret) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers_interpret) (0.5.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers_interpret) (21.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers_interpret) (0.0.49)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers_interpret) (4.63.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=3.0.0->transformers_interpret) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=3.0.0->transformers_interpret) (3.7.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum>=0.3.1->transformers_interpret) (1.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum>=0.3.1->transformers_interpret) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum>=0.3.1->transformers_interpret) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->captum>=0.3.1->transformers_interpret) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.0->transformers_interpret) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.0->transformers_interpret) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.0->transformers_interpret) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.0->transformers_interpret) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.0->transformers_interpret) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.0->transformers_interpret) (7.1.2)\n",
            "Building wheels for collected packages: transformers-interpret\n",
            "  Building wheel for transformers-interpret (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers-interpret: filename=transformers_interpret-0.6.0-py3-none-any.whl size=30723 sha256=3707e28e6e2a6c8eda54c42e31b518081c1201ee2d8bed43184039a795a81d4f\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/d9/23/f98fc0716eaab211a43aa7531c9b096df60dd34d1f0ec316bd\n",
            "Successfully built transformers-interpret\n",
            "Installing collected packages: captum, transformers-interpret\n",
            "Successfully installed captum-0.5.0 transformers-interpret-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers_interpret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKVoDXyc7CIk"
      },
      "outputs": [],
      "source": [
        "from transformers_interpret import SequenceClassificationExplainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7R3GmxE61z00"
      },
      "outputs": [],
      "source": [
        "import transformers_interpret\n",
        "# transformers_interpret.version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwULMQxQo7Ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a6ef4d-cf3f-4c9b-c32d-10ec597e2bfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: captum in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from captum) (3.2.2)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from captum) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from captum) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6->captum) (3.10.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (1.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (3.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->captum) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install captum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGqFr8r15rUl"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "\n",
        "# from transformers import BertTokenizer, BertForQuestionAnswering, BertConfig\n",
        "# from transformers import BertModel\n",
        "\n",
        "from captum.attr import visualization as viz\n",
        "from captum.attr import LayerConductance, LayerIntegratedGradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKXKL-zPZd72"
      },
      "outputs": [],
      "source": [
        "def predicted_class_index(model,input_ids,attention_mask) -> int:\n",
        "        \"Returns predicted class index (int) for model with last calculated `input_ids`\"\n",
        "        if len(input_ids) > 0:\n",
        "            ten = model(input_ids, attention_mask)\n",
        "            preds=torch.Tensor(ten)\n",
        "            pred_class = torch.argmax(torch.softmax(preds, dim=0)[0])\n",
        "            return torch.argmax(torch.softmax(preds, dim=1)[0]).cpu().detach().numpy()\n",
        "\n",
        "        else:\n",
        "            raise InputIdsNotCalculatedError(\"input_ids have not been created yet.`\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cgnjd4oJbfaC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7a63449-510e-4442-9f5c-04ddcd59227e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "selected_index=predicted_class_index(intent_model,input_id,mask)\n",
        "selected_index=int(selected_index)\n",
        "selected_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gviG_Y8zh9pr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6786d5f-5732-4c0c-85fa-1d9f396bddc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[101, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 102]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[101,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 102]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "import torch\n",
        "cls_token_id=101\n",
        "sep_token_id=102\n",
        "ref_token_id=0\n",
        "ref_input_ids = [[cls_token_id] + [ref_token_id] * 24 + [sep_token_id]]\n",
        "# ref_input_ids=[[101, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 102]]\n",
        "print(ref_input_ids)\n",
        "ref_input_ids= torch.Tensor(ref_input_ids).type(torch.long)\n",
        "\n",
        "ref_input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zH0hh0gvXfQn"
      },
      "outputs": [],
      "source": [
        "# pred_probs=torch.Tensor()\n",
        "def custom_forward (  # type: ignore\n",
        "        input_ids: torch.Tensor,\n",
        "        position_ids: torch.Tensor = None,\n",
        "        attention_mask: torch.Tensor = None,\n",
        "    ):\n",
        "\n",
        "        \n",
        "        ten = intent_model(input_ids, attention_mask)\n",
        "        preds=torch.Tensor(ten)\n",
        "\n",
        "\n",
        "        pred_probs = torch.softmax(preds, dim=1)[0][selected_index]\n",
        "        print(pred_probs)\n",
        "        return torch.softmax(preds, dim=1)[:, selected_index]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJvLzmtorAu2"
      },
      "outputs": [],
      "source": [
        "# x=torch.tensor(0.3111)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjHzVMBVGPCO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fb5b28d-bfd4-4478-c03a-f54b01da9ae3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(30522, 768, padding_idx=0)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "my5u_KmCXapv"
      },
      "outputs": [],
      "source": [
        "lig = LayerIntegratedGradients(custom_forward, embedding,input_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrHFqOkByzZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc342fd-ef13-45b8-ebe9-96cea1860b60"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<captum.attr._core.layer.layer_integrated_gradients.LayerIntegratedGradients at 0x7f7396751ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "lig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_jLlMpI0XPB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73877266-4797-4999-b70c-fc427c2c4809"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,  5587, 21507, 11895,  4063,  2201,  2000,  2026,  4556,  6827,\n",
              "          2015,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "input_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4BCXTlx0Zjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a2839b1-3a63-4362-aa69-e620afda59f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[101,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 102]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "ref_input_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3i1Nv4jXKoY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "d85f33d1-fbbc-4d45-cd2e-777685cc6d4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.2805)\n",
            "tensor(0.2772)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-c9151e65cc42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mreturn_convergence_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0minternal_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 \u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/captum/log/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/captum/attr/_core/layer/layer_integrated_gradients.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta, attribute_to_layer_input)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0minternal_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minternal_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m             \u001b[0mreturn_convergence_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m         )\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/captum/attr/_core/integrated_gradients.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[1;32m    280\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madditional_forward_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m             )\n\u001b[1;32m    284\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/captum/attr/_utils/batching.py\u001b[0m in \u001b[0;36m_batch_attribution\u001b[0;34m(attr_method, num_examples, internal_batch_size, n_steps, include_endpoint, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_alphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         current_attr = attr_method._attribute(\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_sizes_and_alphas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         )\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/captum/attr/_core/integrated_gradients.py\u001b[0m in \u001b[0;36m_attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaled_features_tpl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mtarget_ind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_additional_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         )\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/captum/attr/_core/layer/layer_integrated_gradients.py\u001b[0m in \u001b[0;36mgradient_func\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m                     output = _run_forward(\n\u001b[0;32m--> 465\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m                     )\n\u001b[1;32m    467\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/captum/_utils/common.py\u001b[0m in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_forward_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madditional_forward_args\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0;32melse\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m     )\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_select_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-80439e678b3b>\u001b[0m in \u001b[0;36mcustom_forward\u001b[0;34m(input_ids, position_ids, attention_mask)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintent_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mten\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-102caffa55ed>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mdropout_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mlinear_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    992\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m         )\n\u001b[1;32m    996\u001b[0m         encoder_outputs = self.encoder(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m                 \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/captum/attr/_core/layer/layer_integrated_gradients.py\u001b[0m in \u001b[0;36mlayer_forward_hook\u001b[0;34m(module, hook_inputs, hook_outputs, layer_idx)\u001b[0m\n\u001b[1;32m    433\u001b[0m                         ]\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mscattered_inputs_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_outputs_cumsum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mhooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: device(type='cpu')"
          ]
        }
      ],
      "source": [
        "_attributions, delta = lig.attribute(\n",
        "                inputs=input_id,\n",
        "                baselines=ref_input_ids,\n",
        "                return_convergence_delta=True,\n",
        "                internal_batch_size=1,\n",
        "                n_steps=10,\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1L6m6A3gz90P",
        "outputId": "0f4059a8-29dd-40a2-a7e3-311d2ad80682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2c3a480235e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_attribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name '_attribution' is not defined"
          ]
        }
      ],
      "source": [
        "_attribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBonWla0qvWM"
      },
      "outputs": [],
      "source": [
        "attributions_sum=summarize(_attributions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqabL7zyfZK1"
      },
      "outputs": [],
      "source": [
        "attributions_sum.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDGn7xIMK1CK"
      },
      "outputs": [],
      "source": [
        " x=torch.tensor(0.3115)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDSI9EfufVvm"
      },
      "outputs": [],
      "source": [
        "def visualize_attributions(\n",
        "         delta,attributions_sum,pred_prob, pred_class, true_class, attr_class, all_tokens\n",
        "    ):\n",
        "\n",
        "        return viz.VisualizationDataRecord(\n",
        "            attributions_sum,\n",
        "            pred_prob,\n",
        "            pred_class,\n",
        "            true_class,\n",
        "            attr_class,\n",
        "            attributions_sum.sum(),\n",
        "            all_tokens.split(\" \"),\n",
        "            delta,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5m8-lPY4qkr"
      },
      "outputs": [],
      "source": [
        "attr_class=id2label[selected_index]\n",
        "true_class=selected_index\n",
        "pred_class=id2label[selected_index]\n",
        "array_token=input_id.detach().numpy()[0]\n",
        "token=tokenizer.decode(array_token)\n",
        "score_viz=visualize_attributions(delta,attributions_sum,x,pred_class,true_class,attr_class,token)\n",
        "print(score_viz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jL-zqc5YTLQj"
      },
      "outputs": [],
      "source": [
        "token.split(\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gm0-BRUdPX5o"
      },
      "outputs": [],
      "source": [
        "score_viz.word_attributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cgt1s_iK_QQ"
      },
      "outputs": [],
      "source": [
        "score_viz.raw_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OAgCX5WhECd"
      },
      "outputs": [],
      "source": [
        "# html_filepath=None\n",
        "html = viz.visualize_text([score_viz])\n",
        "# if html_filepath:\n",
        "  # if not html_filepath.endswith(\".html\"):\n",
        "    # html_filepath = h/tml_filepath + \".html\"\n",
        "  # with open(html_filepath, \"w\") as html_file:\n",
        "    # html_file.write(html.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FkUkFGH22s5"
      },
      "outputs": [],
      "source": [
        "model_path = 'bert-base-uncased'\n",
        "\n",
        "# load model\n",
        "model=BertModel.from_pretrained('bert-base-cased')\n",
        "# model = BertForQuestionAnswering.from_pretrained(model_path)\n",
        "model.eval()\n",
        "model.zero_grad()\n",
        "\n",
        "# load tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6dtAEwB3AxY"
      },
      "outputs": [],
      "source": [
        "ref_token_id = tokenizer.pad_token_id # A token used for generating token reference\n",
        "sep_token_id = tokenizer.sep_token_id # A token used as a separator between question and text and it is also added to the end of the text.\n",
        "cls_token_id = tokenizer.cls_token_id "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pY1LNaBV3RU4"
      },
      "outputs": [],
      "source": [
        "def construct_whole_bert_embeddings(input_ids, ref_input_ids, \\\n",
        "                                    token_type_ids=None, ref_token_type_ids=None, \\\n",
        "                                    position_ids=None, ref_position_ids=None):\n",
        "    input_embeddings = model.embeddings(input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
        "    ref_input_embeddings = model.embeddings(ref_input_ids, token_type_ids=ref_token_type_ids, position_ids=ref_position_ids)\n",
        "    \n",
        "    return input_embeddings, ref_input_embeddings\n",
        "def construct_input_ref_pair(question, text, ref_token_id, sep_token_id, cls_token_id):\n",
        "    question_ids = tokenizer.encode(question, add_special_tokens=False)\n",
        "    text_ids = tokenizer.encode(text, add_special_tokens=False)\n",
        "\n",
        "    # construct input token ids\n",
        "    input_ids = [cls_token_id] + question_ids + [sep_token_id] + text_ids + [sep_token_id]\n",
        "\n",
        "    # construct reference token ids \n",
        "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(question_ids) + [sep_token_id] + \\\n",
        "        [ref_token_id] * len(text_ids) + [sep_token_id]\n",
        "\n",
        "    return torch.tensor([input_ids]), torch.tensor([ref_input_ids]), len(question_ids)\n",
        "\n",
        "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
        "    seq_len = input_ids.size(1)\n",
        "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(seq_len)]])\n",
        "    ref_token_type_ids = torch.zeros_like(token_type_ids)# * -1\n",
        "    return token_type_ids, ref_token_type_ids\n",
        "\n",
        "def construct_input_ref_pos_id_pair(input_ids):\n",
        "    seq_length = input_ids.size(1)\n",
        "    position_ids = torch.arange(seq_length, dtype=torch.long)\n",
        "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
        "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long)\n",
        "\n",
        "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
        "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
        "    return position_ids, ref_position_ids\n",
        "    \n",
        "def construct_attention_mask(input_ids):\n",
        "    return torch.ones_like(input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9ZsBVFO3U6R"
      },
      "outputs": [],
      "source": [
        "question, text = command, op_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rv-H7vPN3be1"
      },
      "outputs": [],
      "source": [
        "input_ids, ref_input_ids, sep_id = construct_input_ref_pair(question, text, ref_token_id, sep_token_id, cls_token_id)\n",
        "token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, sep_id)\n",
        "position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
        "attention_mask = construct_attention_mask(input_ids)\n",
        "\n",
        "indices = input_ids[0].detach().tolist()\n",
        "all_tokens = tokenizer.convert_ids_to_tokens(indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55W7u8rc3b-M"
      },
      "outputs": [],
      "source": [
        "def summarize_attributions(attributions):\n",
        "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
        "    attributions = attributions / torch.norm(attributions)\n",
        "    return attributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TaT_YAB3fiq"
      },
      "outputs": [],
      "source": [
        "def squad_pos_forward_func2(input_emb, attention_mask=None, position=0):\n",
        "    pred = model(inputs_embeds=input_emb, attention_mask=attention_mask, )\n",
        "    pred = pred[position]\n",
        "    return pred.max(1).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Uj8zw8b3gIG"
      },
      "outputs": [],
      "source": [
        "layer_attrs_start = []\n",
        "layer_attrs_end = []\n",
        "\n",
        "# The token that we would like to examine separately.\n",
        "token_to_explain = 6 # the index of the token that we would like to examine more thoroughly\n",
        "layer_attrs_start_dist = []\n",
        "layer_attrs_end_dist = []\n",
        "\n",
        "input_embeddings, ref_input_embeddings = construct_whole_bert_embeddings(input_ids, ref_input_ids, \\\n",
        "                                         token_type_ids=token_type_ids, ref_token_type_ids=ref_token_type_ids, \\\n",
        "                                         position_ids=position_ids, ref_position_ids=ref_position_ids)\n",
        "\n",
        "for i in range(model.config.num_hidden_layers):\n",
        "    lc = LayerConductance(squad_pos_forward_func2, model.encoder.layer[i])\n",
        "    layer_attributions_start = lc.attribute(inputs=input_embeddings, baselines=ref_input_embeddings, additional_forward_args=(attention_mask, 0))\n",
        "    layer_attributions_end = lc.attribute(inputs=input_embeddings, baselines=ref_input_embeddings, additional_forward_args=(attention_mask, 1))\n",
        "    layer_attrs_start.append(summarize_attributions(layer_attributions_start).cpu().detach().tolist())\n",
        "    layer_attrs_end.append(summarize_attributions(layer_attributions_end).cpu().detach().tolist())\n",
        "\n",
        "    # storing attributions of the token id that we would like to examine in more detail in token_to_explain\n",
        "    layer_attrs_start_dist.append(layer_attributions_start[0,token_to_explain,:].cpu().detach().tolist())\n",
        "    layer_attrs_end_dist.append(layer_attributions_end[0,token_to_explain,:].cpu().detach().tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71mqSjDe3naI"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(15,5))\n",
        "xticklabels=all_tokens\n",
        "yticklabels=list(range(1,13))\n",
        "ax = sns.heatmap(np.array(layer_attrs_start), xticklabels=xticklabels, yticklabels=yticklabels, linewidth=0.2)\n",
        "plt.xlabel('Tokens')\n",
        "plt.ylabel('Layers')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers_interpret\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihME9n6nRxaS",
        "outputId": "34c78c0f-19bd-4d7b-db82-202f00cd93d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers_interpret\n",
            "  Downloading transformers-interpret-0.6.0.tar.gz (35 kB)\n",
            "Collecting transformers>=3.0.0\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 6.5 MB/s \n",
            "\u001b[?25hCollecting captum>=0.3.1\n",
            "  Downloading captum-0.5.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 39.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from captum>=0.3.1->transformers_interpret) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from captum>=0.3.1->transformers_interpret) (1.21.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from captum>=0.3.1->transformers_interpret) (3.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6->captum>=0.3.1->transformers_interpret) (3.10.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers_interpret) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers_interpret) (4.11.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 47.8 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 52.8 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 32.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers_interpret) (3.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers_interpret) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers_interpret) (4.63.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0->transformers_interpret) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=3.0.0->transformers_interpret) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=3.0.0->transformers_interpret) (3.7.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum>=0.3.1->transformers_interpret) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum>=0.3.1->transformers_interpret) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum>=0.3.1->transformers_interpret) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->captum>=0.3.1->transformers_interpret) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.0->transformers_interpret) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.0->transformers_interpret) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.0->transformers_interpret) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.0.0->transformers_interpret) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.0->transformers_interpret) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.0->transformers_interpret) (1.1.0)\n",
            "Building wheels for collected packages: transformers-interpret\n",
            "  Building wheel for transformers-interpret (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers-interpret: filename=transformers_interpret-0.6.0-py3-none-any.whl size=30723 sha256=e476c55dc49cb208d245d756f259590471f8d2252fc5269925ff8d26ffe9d02b\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/d9/23/f98fc0716eaab211a43aa7531c9b096df60dd34d1f0ec316bd\n",
            "Successfully built transformers-interpret\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, captum, transformers-interpret\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed captum-0.5.0 huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.18.0 transformers-interpret-0.6.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWl9w7eKAmb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "8ed5a01e-1262-4dba-ef0a-fc86fcb42410"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d160a85e4464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mattributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls_explainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I love you\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_attributions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mcls_explainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"distilbert_example.html\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'word_attributions'"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from transformers_interpret import SequenceClassificationExplainer\n",
        "\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "cls_explainer = SequenceClassificationExplainer(model, tokenizer)\n",
        "attributions = cls_explainer(\"I love you\")\n",
        "\n",
        "print(attributions.word_attributions)\n",
        "cls_explainer.visualize(\"distilbert_example.html\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hyFtG_OXRk6J"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Intent pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "473d6eb0b1c74041aa6dcd0e23ec93c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3048822791d417f9822780bd436d0f2",
              "IPY_MODEL_d196481c7d85407687b802e2997b5d53",
              "IPY_MODEL_d33f6fdc6d8c498b831e44a20bc1f205"
            ],
            "layout": "IPY_MODEL_5c98d3f02dd64af78553ada2e702485e"
          }
        },
        "a3048822791d417f9822780bd436d0f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ab82d9809d44c64a38e15f902bd8f20",
            "placeholder": "​",
            "style": "IPY_MODEL_ff95d213550240738801915360b16b66",
            "value": "Downloading: 100%"
          }
        },
        "d196481c7d85407687b802e2997b5d53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfc65a49583549f69bed3f0a234b3d3b",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9e5ecc5123346ef81379aa89449428c",
            "value": 231508
          }
        },
        "d33f6fdc6d8c498b831e44a20bc1f205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f09dc2bcc3a4b9c87f5cbb6eb55c6c8",
            "placeholder": "​",
            "style": "IPY_MODEL_c6449f05f56640e69aca3f5b02a1ea73",
            "value": " 226k/226k [00:00&lt;00:00, 1.39MB/s]"
          }
        },
        "5c98d3f02dd64af78553ada2e702485e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ab82d9809d44c64a38e15f902bd8f20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff95d213550240738801915360b16b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfc65a49583549f69bed3f0a234b3d3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9e5ecc5123346ef81379aa89449428c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f09dc2bcc3a4b9c87f5cbb6eb55c6c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6449f05f56640e69aca3f5b02a1ea73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec1958b31b9e48dfb41ef49f18d2f6af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b42e0fd07d77464cbbd1edb920bbb6b1",
              "IPY_MODEL_7eeef912c6114c5c856e1745876c75eb",
              "IPY_MODEL_ff8cdcecf4b848cba5aed0327bd67432"
            ],
            "layout": "IPY_MODEL_9154231defc44ed7b1998db883cffe2f"
          }
        },
        "b42e0fd07d77464cbbd1edb920bbb6b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c092f5eb50b74e20942ef7db335418b8",
            "placeholder": "​",
            "style": "IPY_MODEL_a48fad29930d498ea7a80c7c9e1aa77c",
            "value": "Downloading: 100%"
          }
        },
        "7eeef912c6114c5c856e1745876c75eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b43338cb6e8b41a9b8c367c928367af0",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ade3851ea9c4f5695a54639b2d3956e",
            "value": 28
          }
        },
        "ff8cdcecf4b848cba5aed0327bd67432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19590b55224c4ae8a83bf714c7efbabf",
            "placeholder": "​",
            "style": "IPY_MODEL_6b2c08f3c3704154876537938eb36cf1",
            "value": " 28.0/28.0 [00:00&lt;00:00, 714B/s]"
          }
        },
        "9154231defc44ed7b1998db883cffe2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c092f5eb50b74e20942ef7db335418b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a48fad29930d498ea7a80c7c9e1aa77c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b43338cb6e8b41a9b8c367c928367af0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ade3851ea9c4f5695a54639b2d3956e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19590b55224c4ae8a83bf714c7efbabf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b2c08f3c3704154876537938eb36cf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "179a4d781b6647a7ae80f0bfd3a9641e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a579e767b4484a7090191cf64027054c",
              "IPY_MODEL_66fafb53efda49818aec2622a7d8ff46",
              "IPY_MODEL_ea00c0a68c6f48eca082e9e370ff240b"
            ],
            "layout": "IPY_MODEL_a9f0ea4225454b97923d5aa4cda7eefc"
          }
        },
        "a579e767b4484a7090191cf64027054c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_417497019aa64f47a35ba653912dfedf",
            "placeholder": "​",
            "style": "IPY_MODEL_f7fd6ff052584333b38ac3035d6caad3",
            "value": "Downloading: 100%"
          }
        },
        "66fafb53efda49818aec2622a7d8ff46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d0ebee3115246f89132c4190e2e537c",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80092b154f8d4347be68946896311e8c",
            "value": 570
          }
        },
        "ea00c0a68c6f48eca082e9e370ff240b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2af98ef7ea9249dcb065fb3a13b1314a",
            "placeholder": "​",
            "style": "IPY_MODEL_b612755e8cfd40faa86cbf937f3b7de0",
            "value": " 570/570 [00:00&lt;00:00, 13.6kB/s]"
          }
        },
        "a9f0ea4225454b97923d5aa4cda7eefc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "417497019aa64f47a35ba653912dfedf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7fd6ff052584333b38ac3035d6caad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d0ebee3115246f89132c4190e2e537c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80092b154f8d4347be68946896311e8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2af98ef7ea9249dcb065fb3a13b1314a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b612755e8cfd40faa86cbf937f3b7de0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b732a00daf84e2c858f6211eae1a3f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4fade0f7cb0444d7b648bc58a39240ef",
              "IPY_MODEL_163f5cc329094f33ba162039b1934b38",
              "IPY_MODEL_bbd67b865cd54b9e8ca1fd08b926ab98"
            ],
            "layout": "IPY_MODEL_a656f04ae67944e6afb02ca5452461b1"
          }
        },
        "4fade0f7cb0444d7b648bc58a39240ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ed857289f4e492eb12139c51d612f43",
            "placeholder": "​",
            "style": "IPY_MODEL_d0af96a54165416b9813c2f6d4995382",
            "value": "Downloading: 100%"
          }
        },
        "163f5cc329094f33ba162039b1934b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27f5af0a236549f69448427d4586f6a5",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2815b6ca4bdc497fb4692557285faf39",
            "value": 440473133
          }
        },
        "bbd67b865cd54b9e8ca1fd08b926ab98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96570373118e49d7993473712cec119d",
            "placeholder": "​",
            "style": "IPY_MODEL_f8d79b4cc7364f60939aae424e9aede5",
            "value": " 420M/420M [00:26&lt;00:00, 34.2MB/s]"
          }
        },
        "a656f04ae67944e6afb02ca5452461b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ed857289f4e492eb12139c51d612f43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0af96a54165416b9813c2f6d4995382": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27f5af0a236549f69448427d4586f6a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2815b6ca4bdc497fb4692557285faf39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96570373118e49d7993473712cec119d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8d79b4cc7364f60939aae424e9aede5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}